{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars\n",
    "\n",
    "\n",
    "In this assignment, you will build a web application that scrapes various websites for data related to the Mission to Mars and displays the information in a single HTML page. The following outlines what you need to do.\n",
    "\n",
    "## Step 1 - Scraping\n",
    "\n",
    "Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "* Create a Jupyter Notebook file called `mission_to_mars.ipynb` and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape.\n",
    "\n",
    "### NASA Mars News\n",
    "\n",
    "* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pymongo\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import time\n",
    "import pandas as pd\n",
    "import scrape_mars\n",
    "\n",
    "# Open and execute path\n",
    "executable_path = {'executable_path': 'chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browser visit\n",
    "browser.visit(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info\n",
    "# print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the latest News Title and Paragraph Text\n",
    "# Assign the text to variables\n",
    "news_title = soup.find(\"div\", class_='content_title').text\n",
    "mars_data['news_title'] = news_title\n",
    "# print(news_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_p = soup.find(\"div\", class_='rollover_description_inner').text\n",
    "news_p = soup.find(\"div\", class_='article_teaser_body').text\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browser visit\n",
    "browser.visit(url2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click lead image\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click again for full image\n",
    "browser.click_link_by_partial_text('more info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design an XPATH selector to grab the featured image\n",
    "xpath = '//figure//a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use splinter to click the featured image and bring up the full resolution image\n",
    "results = browser.find_by_xpath(xpath)\n",
    "img = results[0]\n",
    "img.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve final image URL\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "featured_image_url = soup.find(\"img\")[\"src\"]\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather\n",
    "\n",
    "* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "mars_weather = 'Sol 1801 (Aug 30, 2017), Sunny, high -21C/-5F, low -80C/-112F, pressure at 8.82 hPa, daylight 06:09-17:55'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url3 = 'https://twitter.com/marswxreport?lang=en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browser visit\n",
    "browser.visit(url3)\n",
    "html = browser.html\n",
    "# Create soup object\n",
    "soups = bs(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mars_weather = soups.find(\"li\", class_=\"js-stream-item\").find(\"p\", class_=\"TweetTextSize\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape first tweet\n",
    "mars_weather = soups.find(\"li\", class_=\"js-stream-item\").find(\"p\", class_=\"tweet-text\").text\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "* Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to scrape\n",
    "url4='http://space-facts.com/mars/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use read_html to read the data\n",
    "tables = pd.read_html(url4)\n",
    "tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice off DataFrame using normal indexing\n",
    "df = tables[0]\n",
    "df.columns = ['0', '1']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns so that they make sense\n",
    "# df.rename(index=str, columns={\"0\": \"Description\", \"1\": \"Mars Facts\"})\n",
    "df.columns = ['Metric', 'Value']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set columns to index\n",
    "table_html = df.set_index(['Metric', 'Value'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html = df\n",
    "table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTML tables from Pandas using to_html method\n",
    "table_html = df.to_html(classes=\"table table-striped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up table\n",
    "table_html = table_html.replace('\\n', '')\n",
    "table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a file\n",
    "df.to_html('tables.html')\n",
    "print(table_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OSX Users can run this to open the file in a browser, \n",
    "# or you can manually find the file and open it in the browser\n",
    "!open table.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mars' hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url5 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "# Browser visit\n",
    "browser.visit(url5)\n",
    "\n",
    "# Create a Beautiful Soup object\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Child website links for each hemisphere\n",
    "base_url = \"https://astrogeology.usgs.gov\"\n",
    "links = [base_url + item.find(class_=\"description\").a[\"href\"] for item in soup.find_all(\"div\", class_=\"item\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hemisphere title and web URL for each image\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "for url in links:\n",
    "    \n",
    "    # from url to soup\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    # Extract data\n",
    "    title = soup.find(\"div\", class_=\"content\").find(\"h2\", class_=\"title\").text.replace(\" Enhanced\", \"\")\n",
    "    img_url = base_url + soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    \n",
    "    # Store in list\n",
    "    hemisphere_image_urls.append({\"title\": title, \"img_url\": img_url})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit browser\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - MongoDB and Flask Application\n",
    "\n",
    "Use MongoDB with Flask templating to create a new HTML page that displays all of the information that was scraped from the URLs above.\n",
    "\n",
    "* Start by converting your Jupyter notebook into a Python script called `scrape_mars.py` with a function called `scrape` that will execute all of your scraping code from above and return one Python dictionary containing all of the scraped data.\n",
    "\n",
    "* Next, create a route called `/scrape` that will import your `scrape_mars.py` script and call your `scrape` function.\n",
    "\n",
    "  * Store the return value in Mongo as a Python dictionary.\n",
    "\n",
    "* Create a root route `/` that will query your Mongo database and pass the mars data into an HTML template to display the data.\n",
    "\n",
    "* Create a template HTML file called `index.html` that will take the mars data dictionary and display all of the data in the appropriate HTML elements. Use the following as a guide for what the final product should look like, but feel free to create your own design.\n",
    "\n",
    "<strong> Please refer to scrape_mars.py, app.py, and index.html for this part </strong>\n",
    "\n",
    "\n",
    "![final_app_part1.png](Images/final_app_part1.png)\n",
    "![final_app_part2.png](Images/final_app_part2.png)\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Submission\n",
    "\n",
    "To submit your work to BootCampSpot, create a new GitHub repository and upload the following:\n",
    "\n",
    "1. The Jupyter Notebook containing the scraping code used.\n",
    "\n",
    "2. Screenshots of your final application.\n",
    "\n",
    "3. Submit the link to your new repository to BootCampSpot.\n",
    "\n",
    "## Hints\n",
    "\n",
    "* Use Splinter to navigate the sites when needed and BeautifulSoup to help find and parse out the necessary data.\n",
    "\n",
    "* Use Pymongo for CRUD applications for your database. For this homework, you can simply overwrite the existing document each time the `/scrape` url is visited and new data is obtained.\n",
    "\n",
    "* Use Bootstrap to structure your HTML template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visiting https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\n",
      "NASA's social media presence, the InSight mission social media accounts, NASA.gov and SolarSystem.NASA.gov will be honored at the 2019 Webby Awards - \"the Oscars of the Internet.\"\n",
      "visiting: https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\n",
      "visiting https://twitter.com/marswxreport?lang=en\n",
      "InSight sol 144 (2019-04-23) low -98.7ºC (-145.7ºF) high -17.6ºC (0.4ºF)\n",
      "winds from the SW at 4.2 m/s (9.5 mph) gusting to 11.1 m/s (24.8 mph)\n",
      "pressure at 7.40 hPapic.twitter.com/ZbFNWx1Eq6\n",
      "visiting https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\n",
      "getting mars data...\n",
      "{'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA19083_hires.jpg',\n",
      " 'hemisphere_image_urls': [{'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg',\n",
      "                            'title': 'Cerberus Hemisphere'},\n",
      "                           {'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg',\n",
      "                            'title': 'Schiaparelli Hemisphere'},\n",
      "                           {'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg',\n",
      "                            'title': 'Syrtis Major Hemisphere'},\n",
      "                           {'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg',\n",
      "                            'title': 'Valles Marineris Hemisphere'}],\n",
      " 'mars_weather': 'InSight sol 144 (2019-04-23) low -98.7ºC (-145.7ºF) high '\n",
      "                 '-17.6ºC (0.4ºF)\\n'\n",
      "                 'winds from the SW at 4.2 m/s (9.5 mph) gusting to 11.1 m/s '\n",
      "                 '(24.8 mph)\\n'\n",
      "                 'pressure at 7.40 hPapic.twitter.com/ZbFNWx1Eq6',\n",
      " 'news_p': \"NASA's social media presence, the InSight mission social media \"\n",
      "           'accounts, NASA.gov and SolarSystem.NASA.gov will be honored at the '\n",
      "           '2019 Webby Awards - \"the Oscars of the Internet.\"',\n",
      " 'news_title': 'NASA Social Media and Websites Win Webby Awards ',\n",
      " 'table_html': None}\n",
      "{'news_title': 'NASA Social Media and Websites Win Webby Awards ', 'news_p': 'NASA\\'s social media presence, the InSight mission social media accounts, NASA.gov and SolarSystem.NASA.gov will be honored at the 2019 Webby Awards - \"the Oscars of the Internet.\"', 'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA19083_hires.jpg', 'mars_weather': 'InSight sol 144 (2019-04-23) low -98.7ºC (-145.7ºF) high -17.6ºC (0.4ºF)\\nwinds from the SW at 4.2 m/s (9.5 mph) gusting to 11.1 m/s (24.8 mph)\\npressure at 7.40 hPapic.twitter.com/ZbFNWx1Eq6', 'table_html': None, 'hemisphere_image_urls': [{'title': 'Cerberus Hemisphere', 'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'}, {'title': 'Schiaparelli Hemisphere', 'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'}, {'title': 'Syrtis Major Hemisphere', 'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'}, {'title': 'Valles Marineris Hemisphere', 'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]}\n"
     ]
    }
   ],
   "source": [
    "print(scrape_mars.scrape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
